{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1769cdd8-4558-4373-9cc4-1b7aaeac0b4c",
   "metadata": {},
   "source": [
    "# Generate gene sets using several prompts.\n",
    "Run this in the `llm2geneset` environment.\n",
    "\n",
    "*Caution: This notebook uses the OpenAI API. Token costs can add up quickly.*\n",
    "\n",
    "Generates JSON outputs in libs_human/{model}/*.json for downstream use in benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afdec6e-35f4-4052-82f5-9248d3e5a8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from pathlib import Path\n",
    "import json\n",
    "import llm2geneset\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a1f072-52a0-40a8-971a-56f883cddaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_elements(array):\n",
    "    \"\"\"Use regular expression to remove (GO:xxx) substring,  \n",
    "       R-HSA-xxx substrings, and WPxxx substrings\"\"\"\n",
    "    cleaned_array = []\n",
    "    for element in array:\n",
    "        cleaned_element = re.sub(r'\\s*\\(GO:\\d+\\)\\s*|\\s*R-HSA-\\d+\\s*|\\s*WP\\d+\\s*', '', element)\n",
    "        cleaned_array.append(cleaned_element)\n",
    "    return cleaned_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f204121-25b6-4f3f-94f1-58299a95a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_names = [\"KEGG_2021_Human\", \n",
    "             \"Reactome_2022\", \n",
    "             \"WikiPathway_2023_Human\",\n",
    "             \"GO_Biological_Process_2023_sample1000\"]\n",
    "aclient = openai.AsyncClient()\n",
    "models = [\"gpt-4o-mini-2024-07-18\", \"gpt-3.5-turbo-0125\", \"gpt-4o-2024-08-06\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36de3b2f-d13b-4d66-9b11-f8fdd75c5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    for lib_name in lib_names:\n",
    "        gmt = llm2geneset.read_gmt(\"libs_human/gmt/\" + lib_name + \".txt\")\n",
    "        # Generate cleaned version of gene set description w/o identifiers.\n",
    "        descr_cleaned = clean_elements(gmt[\"descr\"])\n",
    "        \n",
    "        # Assemble and save generation results.\n",
    "        gen_res = {}\n",
    "        gen_res[\"lib_name\"] = lib_name\n",
    "        gen_res[\"model\"] = model\n",
    "        gen_res[\"descr\"] = gmt[\"descr\"]\n",
    "        gen_res[\"descr_cleaned\"] = descr_cleaned \n",
    "        gen_res[\"curated_genesets\"] = gmt[\"genes\"]\n",
    "    \n",
    "        with open('libs_human/' + model + '/' + lib_name + '.json', 'w') as json_file:\n",
    "            json.dump(gen_res, json_file, indent=4)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a690cfce-1248-4d52-82a4-7be12b82d339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini-2024-07-18\n",
      "GO_Biological_Process_2023_sample1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:08<00:00, 14.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:59<00:00, 16.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:25<00:00,  6.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:08<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0125\n",
      "GO_Biological_Process_2023_sample1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:55<00:00, 17.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:58<00:00, 17.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:53<00:00, 18.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:58<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-2024-08-06\n",
      "GO_Biological_Process_2023_sample1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [07:31<00:00,  2.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:01<00:00, 16.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:29<00:00, 11.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:13<00:00, 13.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    for lib_name in lib_names:\n",
    "        print(lib_name)\n",
    "        \n",
    "        with open(\"libs_human/\" + model + \"/\" + lib_name + \".json\") as f:\n",
    "            gen_res = json.load(f)\n",
    "        \n",
    "        # Generate genes sets with a system message with role prompt.\n",
    "        start_time1 = time.time()\n",
    "        llm_genes_role = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                           gen_res[\"descr_cleaned\"],\n",
    "                                                           model=model,\n",
    "                                                           prompt_type='basic',\n",
    "                                                           use_sysmsg=True)\n",
    "        end_time1 = time.time()\n",
    "        gen_time_role = end_time1 - start_time1\n",
    "\n",
    "        # Generate gene sets without role prompt.\n",
    "        start_time2 = time.time()\n",
    "        llm_genes_norole = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                             gen_res[\"descr_cleaned\"],\n",
    "                                                             model=model)\n",
    "        end_time2 = time.time()\n",
    "        gen_time_norole = end_time2 - start_time2\n",
    "\n",
    "        # Generate gene sets with reasoning.\n",
    "        start_time3 = time.time()\n",
    "        llm_genes_reason = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                             gen_res[\"descr_cleaned\"],\n",
    "                                                             model=model, \n",
    "                                                             prompt_type='reason')\n",
    "        end_time3 = time.time()\n",
    "        gen_time_reasoning = end_time3 - start_time3\n",
    "\n",
    "        # Generate gene sets with confidence.\n",
    "        start_time4 = time.time()\n",
    "        llm_genes_conf = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                           gen_res[\"descr_cleaned\"],\n",
    "                                                           model=model, \n",
    "                                                           prompt_type='conf')\n",
    "        end_time4 = time.time()\n",
    "        gen_time_conf = end_time4 - start_time4\n",
    "\n",
    "\n",
    "        # Assemble and save generation results.\n",
    "        gen_res[\"gen_time_role\"] = gen_time_role\n",
    "        gen_res[\"gen_time_norole\"] = gen_time_norole\n",
    "        gen_res[\"gen_time_reasoning\"] = gen_time_reasoning\n",
    "        gen_res[\"gen_time_conf\"] = gen_time_conf\n",
    "        gen_res[\"llm_genes_role\"] = llm_genes_role\n",
    "        gen_res[\"llm_genes_norole\"] = llm_genes_norole\n",
    "        gen_res[\"llm_genes_reason\"] = llm_genes_reason\n",
    "        gen_res[\"llm_genes_conf\"] = llm_genes_conf\n",
    "    \n",
    "        with open('libs_human/' + model + '/' + lib_name + '.json', 'w') as json_file:\n",
    "            json.dump(gen_res, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9084cc22-0c91-45c9-a5ab-0e9f7c6f9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0125\n",
      "GO_Biological_Process_2023_sample1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:03<00:00, 15.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:59<00:00, 16.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:59<00:00, 16.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:57<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-2024-08-06\n",
      "GO_Biological_Process_2023_sample1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:08<00:00, 14.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:06<00:00, 15.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:12<00:00, 13.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:21<00:00, 12.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate gene sets for ensembling.\n",
    "for model in models:\n",
    "    print(model)\n",
    "    for lib_name in lib_names:\n",
    "        print(lib_name)\n",
    "        with open(\"libs_human/\" + model + \"/\" + lib_name + \".json\") as f:\n",
    "            gen_res = json.load(f)\n",
    "\n",
    "        # Note seed is needed for ensembling to get different genes each time.\n",
    "        seed = 732456\n",
    "        for i in range(4):\n",
    "            start_time = time.time()\n",
    "            gen_res[\"llm_ensemble_\" + str(i)] = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                                                  gen_res[\"descr_cleaned\"],\n",
    "                                                                                  model=model,\n",
    "                                                                                  seed=seed+i)\n",
    "            end_time = time.time()\n",
    "            gen_res[\"gen_time_ensemble_\" + str(i)] = end_time - start_time\n",
    "\n",
    "        with open('libs_human/' + model + '/' + lib_name + '.json', 'w') as json_file:\n",
    "            json.dump(gen_res, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
