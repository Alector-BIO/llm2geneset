{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1769cdd8-4558-4373-9cc4-1b7aaeac0b4c",
   "metadata": {},
   "source": [
    "# Generate gene sets using several prompts.\n",
    "Run this in the `llm2geneset` environment.\n",
    "\n",
    "*Caution: This notebook uses the OpenAI API. Token costs can add up quickly.*\n",
    "\n",
    "Generates JSON outputs in libs_human/{model}/*.json for downstream use in benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afdec6e-35f4-4052-82f5-9248d3e5a8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from pathlib import Path\n",
    "import json\n",
    "import llm2geneset\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a1f072-52a0-40a8-971a-56f883cddaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_elements(array):\n",
    "    \"\"\"Use regular expression to remove (GO:xxx) substring,  \n",
    "       R-HSA-xxx substrings, and WPxxx substrings\"\"\"\n",
    "    cleaned_array = []\n",
    "    for element in array:\n",
    "        cleaned_element = re.sub(r'\\s*\\(GO:\\d+\\)\\s*|\\s*R-HSA-\\d+\\s*|\\s*WP\\d+\\s*', '', element)\n",
    "        cleaned_array.append(cleaned_element)\n",
    "    return cleaned_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f204121-25b6-4f3f-94f1-58299a95a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_names = [\"KEGG_2021_Human\", \n",
    "             \"Reactome_2022\", \n",
    "             \"WikiPathway_2023_Human\"]\n",
    "aclient = openai.AsyncClient()\n",
    "models = [\"gpt-4o-mini-2024-07-18\", \"gpt-3.5-turbo-0125\", \"gpt-4o-2024-08-06\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36de3b2f-d13b-4d66-9b11-f8fdd75c5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    for lib_name in lib_names:\n",
    "        gmt = llm2geneset.read_gmt(\"libs_human/gmt/\" + lib_name + \".txt\")\n",
    "        # Generate cleaned version of gene set description w/o identifiers.\n",
    "        descr_cleaned = clean_elements(gmt[\"descr\"])\n",
    "        \n",
    "        # Assemble and save generation results.\n",
    "        gen_res = {}\n",
    "        gen_res[\"lib_name\"] = lib_name\n",
    "        gen_res[\"model\"] = model\n",
    "        gen_res[\"descr\"] = gmt[\"descr\"]\n",
    "        gen_res[\"descr_cleaned\"] = descr_cleaned \n",
    "        gen_res[\"curated_genesets\"] = gmt[\"genes\"]\n",
    "    \n",
    "        with open('libs_human/' + model + '/' + lib_name + '.json', 'w') as json_file:\n",
    "            json.dump(gen_res, json_file, indent=4)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a690cfce-1248-4d52-82a4-7be12b82d339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini-2024-07-18\n",
      "KEGG_2021_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:26<00:00, 12.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:15<00:00, 21.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:34<00:00,  9.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:24<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactome_2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [06:51<00:00,  4.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [00:50<00:00, 36.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [00:51<00:00, 35.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [13:21<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiPathway_2023_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [06:41<00:00,  2.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:31<00:00, 25.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:58<00:00, 13.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [06:41<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0125\n",
      "KEGG_2021_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:40<00:00,  7.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:21<00:00, 14.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:16<00:00, 18.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:14<00:00, 21.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactome_2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [00:35<00:00, 51.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [00:33<00:00, 53.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [00:43<00:00, 41.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [00:31<00:00, 57.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiPathway_2023_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [01:38<00:00,  8.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:28<00:00, 28.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:19<00:00, 41.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:31<00:00, 25.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-2024-08-06\n",
      "KEGG_2021_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:32<00:00,  9.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:30<00:00, 10.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:39<00:00,  8.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:34<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactome_2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [01:33<00:00, 19.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [01:55<00:00, 15.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [00:52<00:00, 34.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [06:49<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiPathway_2023_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:44<00:00, 17.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:32<00:00, 24.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [06:46<00:00,  1.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:41<00:00, 19.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    for lib_name in lib_names:\n",
    "        print(lib_name)\n",
    "        \n",
    "        with open(\"libs_human/\" + model + \"/\" + lib_name + \".json\") as f:\n",
    "            gen_res = json.load(f)\n",
    "        \n",
    "        # Generate genes sets with a system message with role prompt.\n",
    "        start_time1 = time.time()\n",
    "        llm_genes_role = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                           gen_res[\"descr_cleaned\"],\n",
    "                                                           model=model,\n",
    "                                                           prompt_type='basic',\n",
    "                                                           use_sysmsg=True)\n",
    "        end_time1 = time.time()\n",
    "        gen_time_role = end_time1 - start_time1\n",
    "\n",
    "        # Generate gene sets without role prompt.\n",
    "        start_time2 = time.time()\n",
    "        llm_genes_norole = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                             gen_res[\"descr_cleaned\"],\n",
    "                                                             model=model)\n",
    "        end_time2 = time.time()\n",
    "        gen_time_norole = end_time2 - start_time2\n",
    "\n",
    "        # Generate gene sets with reasoning.\n",
    "        start_time3 = time.time()\n",
    "        llm_genes_reason = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                             gen_res[\"descr_cleaned\"],\n",
    "                                                             model=model, \n",
    "                                                             prompt_type='reason')\n",
    "        end_time3 = time.time()\n",
    "        gen_time_reasoning = end_time3 - start_time3\n",
    "\n",
    "        # Generate gene sets with confidence.\n",
    "        start_time4 = time.time()\n",
    "        llm_genes_conf = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                           gen_res[\"descr_cleaned\"],\n",
    "                                                           model=model, \n",
    "                                                           prompt_type='conf')\n",
    "        end_time4 = time.time()\n",
    "        gen_time_conf = end_time4 - start_time4\n",
    "\n",
    "\n",
    "        # Assemble and save generation results.\n",
    "        gen_res[\"gen_time_role\"] = gen_time_role\n",
    "        gen_res[\"gen_time_norole\"] = gen_time_norole\n",
    "        gen_res[\"gen_time_reasoning\"] = gen_time_reasoning\n",
    "        gen_res[\"gen_time_conf\"] = gen_time_conf\n",
    "        gen_res[\"llm_genes_role\"] = llm_genes_role\n",
    "        gen_res[\"llm_genes_norole\"] = llm_genes_norole\n",
    "        gen_res[\"llm_genes_reason\"] = llm_genes_reason\n",
    "        gen_res[\"llm_genes_conf\"] = llm_genes_conf\n",
    "    \n",
    "        with open('libs_human/' + model + '/' + lib_name + '.json', 'w') as json_file:\n",
    "            json.dump(gen_res, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9084cc22-0c91-45c9-a5ab-0e9f7c6f9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini-2024-07-18\n",
      "KEGG_2021_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:22<00:00, 14.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:19<00:00, 16.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:20<00:00, 15.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:19<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactome_2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [01:37<00:00, 18.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [04:43<00:00,  6.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [01:39<00:00, 18.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [01:38<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiPathway_2023_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [07:01<00:00,  1.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:45<00:00, 17.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:47<00:00, 16.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [02:47<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0125\n",
      "KEGG_2021_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:44<00:00,  7.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:27<00:00, 11.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:37<00:00,  8.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:46<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactome_2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [01:43<00:00, 17.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [08:04<00:00,  3.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [02:05<00:00, 14.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [07:34<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiPathway_2023_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:53<00:00, 14.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [01:08<00:00, 11.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:52<00:00, 15.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [01:07<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-2024-08-06\n",
      "KEGG_2021_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:31<00:00, 10.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:40<00:00,  7.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:28<00:00, 11.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:30<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactome_2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [02:37<00:00, 11.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [01:43<00:00, 17.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [07:34<00:00,  4.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1818/1818 [02:52<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiPathway_2023_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [07:10<00:00,  1.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:49<00:00, 16.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:59<00:00, 13.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 801/801 [00:53<00:00, 15.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate gene sets for ensembling.\n",
    "for model in models:\n",
    "    print(model)\n",
    "    for lib_name in lib_names:\n",
    "        print(lib_name)\n",
    "        with open(\"libs_human/\" + model + \"/\" + lib_name + \".json\") as f:\n",
    "            gen_res = json.load(f)\n",
    "\n",
    "        # Note seed is needed for ensembling to get different genes each time.\n",
    "        seed = 732456\n",
    "        for i in range(4):\n",
    "            start_time = time.time()\n",
    "            gen_res[\"llm_ensemble_\" + str(i)] = await llm2geneset.get_genes_bench(aclient,\n",
    "                                                                                  gen_res[\"descr_cleaned\"],\n",
    "                                                                                  model=model,\n",
    "                                                                                  seed=seed+i)\n",
    "            end_time = time.time()\n",
    "            gen_res[\"gen_time_ensemble_\" + str(i)] = end_time - start_time\n",
    "\n",
    "        with open('libs_human/' + model + '/' + lib_name + '.json', 'w') as json_file:\n",
    "            json.dump(gen_res, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
