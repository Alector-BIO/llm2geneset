{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from pathlib import Path\n",
    "import json\n",
    "import llm2geneset\n",
    "import time\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "aclient = openai.AsyncClient()\n",
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsai_outputs = pd.read_csv(\"/home/jzhu/llm2geneset/notebooks/gsai_outputs.tsv\", sep=\"\\t\")\n",
    "llm2geneset_outputs = pd.read_csv(\"/home/jzhu/llm2geneset/notebooks/llm2geneset_outputs.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>library</th>\n",
       "      <th>gt_name</th>\n",
       "      <th>gsai_name</th>\n",
       "      <th>gsai_ROUGE1</th>\n",
       "      <th>gsai_ROUGE2</th>\n",
       "      <th>gsai_ROUGEL</th>\n",
       "      <th>gsai_csim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>KEGG_2021_Human</td>\n",
       "      <td>ABC transporters</td>\n",
       "      <td>Transmembrane transport and cellular detoxific...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.537227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>KEGG_2021_Human</td>\n",
       "      <td>AGE-RAGE signaling pathway in diabetic complic...</td>\n",
       "      <td>Inflammatory signaling and immune response reg...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.370827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model          library  \\\n",
       "0  gpt-3.5-turbo-0125  KEGG_2021_Human   \n",
       "1  gpt-3.5-turbo-0125  KEGG_2021_Human   \n",
       "\n",
       "                                             gt_name  \\\n",
       "0                                   ABC transporters   \n",
       "1  AGE-RAGE signaling pathway in diabetic complic...   \n",
       "\n",
       "                                           gsai_name  gsai_ROUGE1  \\\n",
       "0  Transmembrane transport and cellular detoxific...     0.500000   \n",
       "1  Inflammatory signaling and immune response reg...     0.142857   \n",
       "\n",
       "   gsai_ROUGE2  gsai_ROUGEL  gsai_csim  \n",
       "0          0.0     0.285714   0.537227  \n",
       "1          0.0     0.153846   0.370827  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsai_outputs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEGG_2021_Human\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.44s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.90s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.87s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "100%|██████████| 1/1 [00:14<00:00, 14.98s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.21s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.08s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.70s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.57s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.24s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.37s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.22s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "100%|██████████| 1/1 [00:30<00:00, 30.06s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.63s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.72s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.74s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.87s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.30s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.17s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.45s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.28s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.36s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "100%|██████████| 1/1 [00:17<00:00, 17.40s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.61s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.22s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.65s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.05s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.50s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.26s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.45s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.33s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.30s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.69s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.93s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.15s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.14s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.41s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "100%|██████████| 1/1 [00:11<00:00, 11.83s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.40s/it]\n"
     ]
    }
   ],
   "source": [
    "models = [\"gpt-3.5-turbo-0125\",\"gpt-4o-2024-05-13\"]\n",
    "lib_names = [\"KEGG_2021_Human\",\n",
    "             \"Reactome_2022\", \n",
    "             \"WikiPathway_2023_Human\"]\n",
    "models = [\"gpt-3.5-turbo-0125\"]\n",
    "lib_names = [\"KEGG_2021_Human\"]\n",
    "\n",
    "ouput = []\n",
    "for model in models:    \n",
    "    for lib_name in lib_names:\n",
    "        print(lib_name)\n",
    "        with open(\"libs_human/\" + model + \"/\" + lib_name + \".json\") as f:\n",
    "            gen_res = json.load(f)\n",
    "\n",
    "        test_sets = gen_res[\"curated_genesets\"]\n",
    "        test_descr = gen_res[\"descr_cleaned\"]\n",
    "        # choose the gene sets that GSAI ROUGE1>0\n",
    "        gsai_sets = gsai_outputs[(gsai_outputs.gsai_ROUGE1>0) & (gsai_outputs.library==lib_name)].gt_name.values\n",
    "\n",
    "        # choose the gene sets that LLM2geneset ROUGE1>0\n",
    "        llm2geneset_sets = llm2geneset_outputs[(llm2geneset_outputs.llm2geneset_ROUGE1>0) & (llm2geneset_outputs.library==lib_name)].gt_name.values\n",
    "\n",
    "        # pick the gene sets that both GSAI and LLM2geneset has ROUGE1>1\n",
    "        intersect_set = set(llm2geneset_sets).intersection(set(gsai_sets))\n",
    "\n",
    "        # select the intersect test sets \n",
    "        set_indices = np.where(np.isin(test_descr, list(intersect_set)))[0]\n",
    "\n",
    "        # choose 2 random gene sets for 50 times\n",
    "        for i in range(50):\n",
    "            # draw 2 random gene sets\n",
    "            random_indices = np.random.randint(0, len(set_indices), size=2)\n",
    "            selected_test_descr=[test_descr[set_indices[i]] for i in random_indices]\n",
    "            selected_test_sets=[test_sets[set_indices[i]] for i in random_indices]\n",
    "            # combine the genes in the gene set\n",
    "            selected_test_sets = list(set(selected_test_sets[0]).union(set(selected_test_sets[1])))\n",
    "            # shuffle the genese within the gene set\n",
    "            np.random.shuffle(selected_test_sets)\n",
    "            # get the embedding of the combined gene set name\n",
    "            gt_name = [', '.join(selected_test_descr)]\n",
    "            gt_emb = llm2geneset.get_embeddings(client, gt_name)\n",
    "\n",
    "            # use GSAI to generate geneset name\n",
    "            gsai_res = await llm2geneset.gsai(aclient, [selected_test_sets], model=model, n_retry=3)\n",
    "            gsai_name = [i['name'] for i in gsai_res]\n",
    "            gsai_name_emb = llm2geneset.get_embeddings(client, gsai_name)\n",
    "            # evaluate gsai proposed gene set name\n",
    "            scores = scorer.score(gt_name[0], gsai_name[0])\n",
    "            gsai_rouge1= scores['rouge1'].recall\n",
    "            gsai_rouge2= scores['rouge2'].recall\n",
    "            gsai_rougeL= scores['rougeL'].fmeasure      \n",
    "            gsai_csim = cosine_similarity(gt_emb,gsai_name_emb).squeeze()\n",
    "            \n",
    "            x={\"model\":model,\n",
    "               \"library\":lib_name,\n",
    "               \"gt_name\":gt_name[0],\n",
    "               \"name\":gsai_name[0],\n",
    "               \"ROUGE1\":gsai_rouge1,\n",
    "               \"ROUGE2\":gsai_rouge2,   \n",
    "               \"ROUGEL\":gsai_rougeL,                  \n",
    "               \"csim\":gsai_csim,\n",
    "               \"method\":\"GSAI\"}    \n",
    "        \n",
    "            ouput.append(x)\n",
    "\n",
    "            # use LLM2geneset to generate geneset name\n",
    "            llm2geneset_res = await llm2geneset.gs_proposal(aclient, [selected_test_sets], model=model, n_retry=3)\n",
    "            # llm2geneset proposed gene set names\n",
    "            names = [gene_set[0] for gene_set in llm2geneset_res[0]]\n",
    "            # hypergeometric p-vals for proposed gene sets \n",
    "            pvals=[gene_set[1] for gene_set in llm2geneset_res[0]]\n",
    "            # correct the pvals\n",
    "            _, pvals_corrected, _, _ = multipletests(pvals, method='bonferroni')\n",
    "            # select gene sets with adj pvals<0.01\n",
    "            indices = np.where(pvals_corrected<0.01)\n",
    "            llm2geneset_name = [', '.join(np.array(names)[indices])]\n",
    "            llm2geneset_name_emb = llm2geneset.get_embeddings(client, llm2geneset_name)\n",
    "            # evaluate llm2geneset proposed gene set name\n",
    "            scores = scorer.score(gt_name[0], llm2geneset_name[0])\n",
    "            llm2geneset_rouge1= scores['rouge1'].recall\n",
    "            llm2geneset_rouge2= scores['rouge2'].recall\n",
    "            llm2geneset_rougeL= scores['rougeL'].fmeasure      \n",
    "            llm2geneset_csim = cosine_similarity(gt_emb,llm2geneset_name_emb).squeeze()\n",
    "\n",
    "            x={\"model\":model,\n",
    "               \"library\":lib_name,\n",
    "               \"gt_name\":gt_name[0],\n",
    "               \"name\":llm2geneset_name[0],\n",
    "               \"ROUGE1\":llm2geneset_rouge1,\n",
    "               \"ROUGE2\":llm2geneset_rouge2,   \n",
    "               \"ROUGEL\":llm2geneset_rougeL,                  \n",
    "               \"csim\":llm2geneset_csim,\n",
    "               \"method\":\"LLM2geneset\"}    \n",
    "        \n",
    "            ouput.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('mix_genesets_outputs.tsv', sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
